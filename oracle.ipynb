{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ufc_fights.csv')\n",
    "# print(df.columns)\n",
    "print(', '.join(df.columns))\n",
    "# print(df.head())\n",
    "# print(df.info())\n",
    "# print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze and handle missing data\n",
    "\n",
    "def missing_value_analysis(df):\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_values_percentage = (missing_values / len(df)) * 100\n",
    "    missing_values_table = pd.concat([missing_values, missing_values_percentage], axis=1)\n",
    "    missing_values_table = missing_values_table.rename(columns={0: 'Missing Values', 1: 'Percentage'})\n",
    "\n",
    "    return missing_values_table[missing_values_table['Missing Values'] > 0].sort_values(by='Percentage', ascending=False)\n",
    "\n",
    "\n",
    "missing_data = missing_value_analysis(df)\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "def handle_missing_values(df):\n",
    "   \n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # 1.Drop EmptyArena column as it's not needed for meaningful analysis\n",
    "    print(f\"Dropping EmptyArena column as it's not needed for analysis\")\n",
    "    if 'EmptyArena' in df_processed.columns:\n",
    "        df_processed = df_processed.drop('EmptyArena', axis=1)\n",
    "    \n",
    "    # 2.Handle FinishDetails (55.70% missing)\n",
    "    print(\"Creating indicator for FinishDetails column\")\n",
    "    df_processed['FinishDetails_present'] = df_processed['FinishDetails'].notnull().astype(int)\n",
    "    df_processed['FinishDetails_clean'] = df_processed['FinishDetails'].fillna(\"Not Recorded\")\n",
    "    \n",
    "    # 3.Handle Match Weight Class Rank columns\n",
    "    print(\"Creating indicators and categories for BMatchWCRank and RMatchWCRank\")\n",
    "    # For Blue corner\n",
    "    df_processed['BMatchWCRank_present'] = df_processed['BMatchWCRank'].notnull().astype(int)\n",
    "    # For Red corner\n",
    "    df_processed['RMatchWCRank_present'] = df_processed['RMatchWCRank'].notnull().astype(int)\n",
    "    \n",
    "    # 4.Create ordinal categories for ranks\n",
    "    if 'BMatchWCRank' in df_processed.columns and pd.api.types.is_numeric_dtype(df_processed['BMatchWCRank']):\n",
    "        # Convert to float to ensure NaN values are handled properly\n",
    "        rank_values = df_processed['BMatchWCRank'].astype(float)\n",
    "        # Create a mask for NaN values\n",
    "        na_mask = rank_values.isna()\n",
    "        # Create categories for non-NaN values\n",
    "        cats = pd.cut(rank_values[~na_mask], \n",
    "                     bins=[0, 10, 25, 50, 100, float('inf')],\n",
    "                     labels=['Top 10', '11-25', '26-50', '51-100', '100+'],\n",
    "                     include_lowest=True)\n",
    "        # Initialize result series with proper size\n",
    "        result = pd.Series(index=rank_values.index, dtype='object')\n",
    "        # Assign categorized values\n",
    "        result[~na_mask] = cats\n",
    "        # Assign 'Unranked' to NaN positions\n",
    "        result[na_mask] = 'Unranked'\n",
    "        # Create final categorical with all possible values\n",
    "        all_categories = ['Top 10', '11-25', '26-50', '51-100', '100+', 'Unranked']\n",
    "        df_processed['BMatchWCRank_cat'] = pd.Categorical(result, categories=all_categories)\n",
    "    \n",
    "    if 'RMatchWCRank' in df_processed.columns and pd.api.types.is_numeric_dtype(df_processed['RMatchWCRank']):\n",
    "        # Convert to float to ensure NaN values are handled properly\n",
    "        rank_values = df_processed['RMatchWCRank'].astype(float)\n",
    "        # Create a mask for NaN values\n",
    "        na_mask = rank_values.isna()\n",
    "        # Create categories for non-NaN values\n",
    "        cats = pd.cut(rank_values[~na_mask], \n",
    "                     bins=[0, 10, 25, 50, 100, float('inf')],\n",
    "                     labels=['Top 10', '11-25', '26-50', '51-100', '100+'],\n",
    "                     include_lowest=True)\n",
    "        # Initialize result series with proper size\n",
    "        result = pd.Series(index=rank_values.index, dtype='object')\n",
    "        # Assign categorized values\n",
    "        result[~na_mask] = cats\n",
    "        # Assign 'Unranked' to NaN positions\n",
    "        result[na_mask] = 'Unranked'\n",
    "        # Create final categorical with all possible values\n",
    "        all_categories = ['Top 10', '11-25', '26-50', '51-100', '100+', 'Unranked']\n",
    "        df_processed['RMatchWCRank_cat'] = pd.Categorical(result, categories=all_categories)\n",
    "    \n",
    "    # 5.Handle extreme missing values (>95%) - mostly weight class rankings\n",
    "    extreme_missing_cols = missing_data[missing_data['Percentage'] > 95].index.tolist()\n",
    "    print(f\"Creating binary indicators for {len(extreme_missing_cols)} columns with >95% missing values\")\n",
    "    \n",
    "    for col in extreme_missing_cols:\n",
    "        df_processed[f\"{col}_present\"] = df_processed[col].notnull().astype(int)\n",
    "    \n",
    "    # 6.Create aggregated indicators for weight class rankings\n",
    "    ranking_cols = [col for col in df_processed.columns if 'Rank' in col and col in extreme_missing_cols]\n",
    "    \n",
    "    # Aggregate by corner (blue/red)\n",
    "    if ranking_cols:\n",
    "        blue_rank_cols = [col for col in ranking_cols if col.startswith('B')]\n",
    "        red_rank_cols = [col for col in ranking_cols if col.startswith('R')]\n",
    "        \n",
    "        if blue_rank_cols:\n",
    "            df_processed['blue_has_any_rank'] = df_processed[blue_rank_cols].notnull().any(axis=1).astype(int)\n",
    "        if red_rank_cols:\n",
    "            df_processed['red_has_any_rank'] = df_processed[red_rank_cols].notnull().any(axis=1).astype(int)\n",
    "\n",
    "\n",
    "     # 7. Handle columns with low data values missing (<21%)\n",
    "    low_missing_cols = missing_data[missing_data['Percentage'] < 21].index.tolist()\n",
    "    \n",
    "    print(f\"Standard imputation for {len(low_missing_cols)} columns with <23% missing values\")\n",
    "    \n",
    "    for col in low_missing_cols:\n",
    "        if col in df_processed.columns:\n",
    "            # For numeric columns\n",
    "            if pd.api.types.is_numeric_dtype(df_processed[col]):\n",
    "                # Impute with median\n",
    "                median_val = df_processed[col].median()\n",
    "                df_processed[col] = df_processed[col].fillna(median_val)\n",
    "                print(f\"  - Imputed {col} with median: {median_val}\")\n",
    "            # For categorical/object columns\n",
    "            else:\n",
    "                # Impute with mode\n",
    "                mode_val = df_processed[col].mode()[0] if not df_processed[col].mode().empty else \"Unknown\"\n",
    "                df_processed[col] = df_processed[col].fillna(mode_val)\n",
    "                print(f\"  - Imputed {col} with mode: {mode_val}\")       \n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "df_processed = handle_missing_values(df)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify results\n",
    "print(\"\\nVerifying results after processing\")\n",
    "missing_after = missing_value_analysis(df_processed.drop([col for col in df_processed.columns \n",
    "                                       if col.endswith('_present') or col.endswith('_cat') or col.endswith('_clean')], axis=1))\n",
    "print(\"Original columns with missing values after processing:\")\n",
    "if len(missing_after) > 0:\n",
    "    display(missing_after)\n",
    "else:\n",
    "    print(\"No missing values remain in processed original columns!\")\n",
    "\n",
    "# Save processed dataset\n",
    "df_processed.to_csv('processed_fighting_data.csv', index=False)\n",
    "print(\"\\nProcessed dataset saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
